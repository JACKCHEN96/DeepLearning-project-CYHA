{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columbia University\n",
    "### ECBM E4040 Neural Networks and Deep Learning. Fall 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataprocess \n",
    "\n",
    "In this file, we are going to implement: \n",
    "\n",
    "(1) Read data\n",
    "\n",
    "(2) Process data\n",
    "\n",
    "(3) Convert to specific type for using\n",
    "\n",
    "(4) Start and output\n",
    "<br><br>\n",
    "#### PS: In every several lines we create comments for better understanding the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chiahohsiung/.pyenv/versions/anaconda3-5.3.1/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/chiahohsiung/.pyenv/versions/anaconda3-5.3.1/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/chiahohsiung/.pyenv/versions/anaconda3-5.3.1/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/chiahohsiung/.pyenv/versions/anaconda3-5.3.1/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/chiahohsiung/.pyenv/versions/anaconda3-5.3.1/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/chiahohsiung/.pyenv/versions/anaconda3-5.3.1/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import random\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_train(train_path, train_mat, train_tfrecords, val_tfrecords):\n",
    "    num_total = 33402\n",
    "    num_train = 30062\n",
    "    num_val = 3340\n",
    "    writer_train = tf.python_io.TFRecordWriter(train_tfrecords)\n",
    "    writer_val = tf.python_io.TFRecordWriter(val_tfrecords)\n",
    "\n",
    "    num_train_c = num_train\n",
    "    num_val_c = num_val\n",
    "    # Load paths to each images\n",
    "    images_path = tf.gfile.Glob(os.path.join(train_path, '*.png'))\n",
    "\n",
    "\n",
    "    # read .mat file \n",
    "    f = h5py.File(train_mat, 'r')\n",
    "    for i in range(1, num_total):\n",
    "        if i % 100 == 0:\n",
    "            print ('(%d/%d) ' % (i, num_total))\n",
    "\n",
    "        # Final goal: tf.train.Example containing image(input) and length, digits(ground truth)\n",
    "        # Pick up paths one by one from the list \n",
    "        image_path = images_path[i-1]\n",
    "        # Extract each image's index, for example get 3974 from './data/train/3975.png' \n",
    "        index = int(image_path.split('/')[-1].split('.')[0]) - 1\n",
    "        #Extract information of corresponding bbox of each image\n",
    "        bbox = {}\n",
    "        item = f['digitStruct']['bbox'][index].item()\n",
    "        for key in ['label', 'left', 'top', 'width', 'height']:\n",
    "            attr = f[item][key]\n",
    "            if len(attr) > 1:\n",
    "                vals = []\n",
    "                for j in range(len(attr)):               \n",
    "                    vals.append(f[attr.value[j].item()].value[0][0])\n",
    "            else:\n",
    "                vals.append(attr.value[0][0])\n",
    "\n",
    "            bbox[key] = vals\n",
    "\n",
    "        # Get labels from the dict\n",
    "        labels = bbox['label']\n",
    "        length = len(labels)\n",
    "        # Transfer labels into list of length 5 digits, for example digits = [1, 2, 0, 10 ,10] when labels_of_digits = [1, 2, 0]\n",
    "        digits = [10, 10, 10, 10, 10]   # digit 10 represents no digit\n",
    "        # If the length of the labels is bigger than five, discard this example\n",
    "        if length > 5:\n",
    "            # Substract 1 from the number of data \n",
    "            if i <= num_val:\n",
    "                num_val_c -= 1\n",
    "            else:\n",
    "                num_train_c -= 1\n",
    "            continue\n",
    "        # Transfer labels into list of length 5 digits, for example digits = [1, 2, 0, 10 ,10] when labels_of_digits = [1, 2, 0]\n",
    "        for idx, label in enumerate(labels):  \n",
    "            if label == 10: # label 10 is essentially digit zero\n",
    "                digits[idx] = 0  \n",
    "            else:\n",
    "                digits[idx] = int(label) \n",
    "\n",
    "        # Get blue boxes' positions and dimensions from the dict\n",
    "        # *map() function returns a list of the results after applying the given function to each item of a given iterable \n",
    "        # This statement might have the same function of attrs_left = attrs['left'], attrs_top = attrs['top], ...\n",
    "        bbox_left, bbox_top, bbox_width, bbox_height = map(lambda x: [int(i) for i in x], [bbox['left'], bbox['top'], bbox['width'], bbox['height']])\n",
    "        min_left, min_top, max_right, max_bottom = (min(bbox_left),\n",
    "                                                    min(bbox_top),\n",
    "                                                    max(map(lambda x, y: x + y, bbox_left, bbox_width)),\n",
    "                                                    max(map(lambda x, y: x + y, bbox_top, bbox_height)))\n",
    "        c_x, c_y, max_side = ((min_left + max_right) / 2.0,\n",
    "                                        (min_top + max_bottom) / 2.0,\n",
    "                                        max(max_right - min_left, max_bottom - min_top))\n",
    "        rbox_left, rbox_top, rbox_width, rbox_height = (c_x - max_side / 2.0,\n",
    "                                                        c_y - max_side / 2.0,\n",
    "                                                        max_side,\n",
    "                                                        max_side)\n",
    "        cropped_left, cropped_top, cropped_width, cropped_height = (int(round(rbox_left - 0.15 * rbox_width)),\n",
    "                                                                    int(round(rbox_top - 0.15 * rbox_height)),\n",
    "                                                                    int(round(rbox_width * 1.3)),\n",
    "                                                                    int(round(rbox_height * 1.3)))\n",
    "\n",
    "        # Crop the image by the enlarged blue box and resize the cropped image to 64x64 and turn it into Python bytes\n",
    "        image = Image.open(image_path)\n",
    "        image = image.crop([cropped_left, cropped_top, cropped_left + cropped_width, cropped_top + cropped_height])\n",
    "        image = np.array(image.resize([64, 64])).tobytes()\n",
    "        \n",
    "        # Put image(input) and length, digits(ground truth) into a tf.train.Example\n",
    "        # tf.train.Example isnâ€™t a normal Python class, but a protocol buffer.\n",
    "        # Later use a tf.python_io.TFRecordWriter to write it to disk.\n",
    "        image_featured = tf.train.Feature(bytes_list=tf.train.BytesList(value=[image]))\n",
    "        length_featured = tf.train.Feature(int64_list=tf.train.Int64List(value=[length]))\n",
    "        digits_featured = tf.train.Feature(int64_list=tf.train.Int64List(value=digits))\n",
    "\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'image': image_featured,\n",
    "            'length': length_featured,\n",
    "            'digits': digits_featured\n",
    "        }))\n",
    "        if i <= num_val:\n",
    "            writer_val.write(example.SerializeToString())\n",
    "        else:\n",
    "            writer_train.write(example.SerializeToString())\n",
    "    \n",
    "    num_train = num_train_c\n",
    "    num_val = num_val_c\n",
    "    writer_train.close()\n",
    "    writer_val.close()\n",
    "    return num_train, num_val\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test(test_path, test_mat, test_tfrecords):\n",
    "    num_test = 13068\n",
    "    writer_test = tf.python_io.TFRecordWriter(test_tfrecords)\n",
    "\n",
    "\n",
    "    # Load paths to each images\n",
    "    images_path = tf.gfile.Glob(os.path.join(test_path, '*.png'))\n",
    "\n",
    "    # read .mat file \n",
    "    f = h5py.File(test_mat, 'r')\n",
    "    for i in range(1, num_test):\n",
    "        if i % 100 == 0:\n",
    "            print ('(%d/%d) ' % (i, num_test))\n",
    "\n",
    "        # Final goal: tf.train.Example containing image(input) and length, digits(ground truth)\n",
    "        image_path = images_path[i-1]\n",
    "        index = int(image_path.split('/')[-1].split('.')[0]) - 1\n",
    "        #Extract information of corresponding bbox of each image\n",
    "        bbox = {}\n",
    "        item = f['digitStruct']['bbox'][index].item()\n",
    "        for key in ['label', 'left', 'top', 'width', 'height']:\n",
    "            attr = f[item][key]\n",
    "            if len(attr) > 1:\n",
    "                vals = []\n",
    "                for j in range(len(attr)):               \n",
    "                    vals.append(f[attr.value[j].item()].value[0][0])\n",
    "            else:\n",
    "                vals.append(attr.value[0][0])\n",
    "\n",
    "            bbox[key] = vals\n",
    "\n",
    "\n",
    "        labels = bbox['label']\n",
    "        length = len(labels)\n",
    "        # Transfer labels into list of length 5 digits, for example digits = [1, 2, 0, 10 ,10] when labels_of_digits = [1, 2, 0]\n",
    "        digits = [10, 10, 10, 10, 10]   # digit 10 represents no digit\n",
    "        if length > 5:\n",
    "            num_test -= 1\n",
    "            continue\n",
    "        for idx, label in enumerate(labels):  \n",
    "            if label == 10: # label 10 is essentially digit zero\n",
    "                digits[idx] = 0  \n",
    "            else:\n",
    "                digits[idx] = int(label) \n",
    "\n",
    "        # Get blue boxes' positions and dimensions from the dict\n",
    "        # *map() function returns a list of the results after applying the given function to each item of a given iterable \n",
    "        # This statement might have the same function of attrs_left = attrs['left'], attrs_top = attrs['top], ...\n",
    "        bbox_left, bbox_top, bbox_width, bbox_height = map(lambda x: [int(i) for i in x], [bbox['left'], bbox['top'], bbox['width'], bbox['height']])\n",
    "        min_left, min_top, max_right, max_bottom = (min(bbox_left),\n",
    "                                                    min(bbox_top),\n",
    "                                                    max(map(lambda x, y: x + y, bbox_left, bbox_width)),\n",
    "                                                    max(map(lambda x, y: x + y, bbox_top, bbox_height)))\n",
    "        c_x, c_y, max_side = ((min_left + max_right) / 2.0,\n",
    "                                        (min_top + max_bottom) / 2.0,\n",
    "                                        max(max_right - min_left, max_bottom - min_top))\n",
    "        rbox_left, rbox_top, rbox_width, rbox_height = (c_x - max_side / 2.0,\n",
    "                                                        c_y - max_side / 2.0,\n",
    "                                                        max_side,\n",
    "                                                        max_side)\n",
    "        cropped_left, cropped_top, cropped_width, cropped_height = (int(round(rbox_left - 0.15 * rbox_width)),\n",
    "                                                                    int(round(rbox_top - 0.15 * rbox_height)),\n",
    "                                                                    int(round(rbox_width * 1.3)),\n",
    "                                                                    int(round(rbox_height * 1.3)))\n",
    "\n",
    "        image = Image.open(image_path)\n",
    "        image = image.crop([cropped_left, cropped_top, cropped_left + cropped_width, cropped_top + cropped_height])\n",
    "        image = np.array(image.resize([64, 64])).tobytes()\n",
    "\n",
    "        image_featured = tf.train.Feature(bytes_list=tf.train.BytesList(value=[image]))\n",
    "        length_featured = tf.train.Feature(int64_list=tf.train.Int64List(value=[length]))\n",
    "        digits_featured = tf.train.Feature(int64_list=tf.train.Int64List(value=digits))\n",
    "\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'image': image_featured,\n",
    "            'length': length_featured,\n",
    "            'digits': digits_featured\n",
    "        }))\n",
    "        writer_test.write(example.SerializeToString())\n",
    "        \n",
    "\n",
    "    writer_test.close()\n",
    "    return num_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/13050) \n",
      "(200/13031) \n",
      "(300/13020) \n",
      "(400/12993) \n",
      "(500/12976) \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0fa254b63c7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#num_train, num_val = preprocess_train(train_path, train_mat, train_tfrecords, val_tfrecords)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mnum_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_tfrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of training examples'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-e6f2c85ce775>\u001b[0m in \u001b[0;36mpreprocess_test\u001b[0;34m(test_path, test_mat, test_tfrecords)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m#Extract information of corresponding bbox of each image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'digitStruct'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bbox'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'top'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'width'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'height'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/envs/envTF113/lib/python3.6/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0mfspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;31m# Patch up the output for NumPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set up paths to raw data\n",
    "train_path = './data/train'\n",
    "test_path = './data/test'\n",
    "train_mat = './data/train/digitStruct.mat'\n",
    "test_mat = './data/test/digitStruct.mat'\n",
    "\n",
    "# Define paths to store processed data\n",
    "train_tfrecords = os.path.join('./data', 'train.tfrecords')\n",
    "val_tfrecords = os.path.join('./data', 'val.tfrecords')\n",
    "test_tfrecords = os.path.join('./data', 'test.tfrecords')\n",
    "meta_file = os.path.join('./data', 'meta.json')\n",
    "\n",
    "num_train, num_val = preprocess_train(train_path, train_mat, train_tfrecords, val_tfrecords)\n",
    "num_test = preprocess_test(test_path, test_mat, test_tfrecords)\n",
    "\n",
    "print('Number of training examples', num_train)\n",
    "print('Number of validation examples', num_val)\n",
    "print('Number of test examples', num_test)\n",
    "\n",
    "# Write numbers of training, validation, test data into meta file for further call\n",
    "with open(path_to_tfrecords_meta_file, 'w') as f:\n",
    "        content = {\n",
    "            'num_examples': {\n",
    "                'train': num_train,\n",
    "                'val': num_val,\n",
    "                'test': num_test\n",
    "            }\n",
    "        }\n",
    "        json.dump(content, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:envTF113] *",
   "language": "python",
   "name": "conda-env-envTF113-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
