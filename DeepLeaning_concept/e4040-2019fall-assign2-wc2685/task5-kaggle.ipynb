{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECBM E4040 - Assignment 2- Task 5: Kaggle Open-ended Competition\n",
    "\n",
    "Kaggle is a platform for predictive modelling and analytics competitions in which companies and researchers post data and statisticians and data miners compete to produce the best models for predicting and describing the data.\n",
    "\n",
    "If you don't have a Kaggle account, feel free to join at [www.kaggle.com](https://www.kaggle.com). To let the CAs do the grading more conveniently, please __use Lionmail to join Kaggle__ and __use UNI as your username__.\n",
    "\n",
    "The website for this competition is: \n",
    "https://www.kaggle.com/c/e4040fall2019-assignment-2-task-5\n",
    "\n",
    "You can find detailed description about this in-class competition on the website above. Please read carefully and follow the instructions.\n",
    "\n",
    "<span style=\"color:red\">__TODO__:</span>\n",
    "1. Train a custom model for the bottle dataset classification problem. You are free to use any methods taught in the class or found by yourself on the Internet (ALWAYS provide reference to the source) but __TF 2.0 is not allowed to use in this competition__. General training methods include:\n",
    "    * Dropout\n",
    "    * Batch normalization\n",
    "    * Early stopping\n",
    "    * l1-norm & l2-norm penalization\n",
    "2. You'll be given the test set to generate your predictions (70% public + 30% private, but you don't know which ones are public/private). Achieve 70% accuracy on the public test set. The accuracy will be shown on the public leaderboard once you submit your prediction .csv file. The private leaderboard would be released after the competition. The final ranking would based on that result, not the public one.\n",
    "3. \n",
    "\n",
    "    * Report your results on the Kaggle, for comparison with other students' optimal results (you can do this several times). \n",
    "    * Save your best model, using Github Classroom, at the same time when you submit the homework files into Courseworks. See instructions below. \n",
    "\n",
    "__Hint__: You can start from what you implemented in task 4. Another classic classification model named 'VGG16' can also be easily implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW Submission Details:\n",
    "There are three components to reporting the results of this task: \n",
    "\n",
    "**(A) Submission (up to 20 submissions each day) of the .csv prediction file throught the Kaggle platform;**. You should start doing this __VERY early__, so that students can compare their work as they are making progress with model optimization.\n",
    "\n",
    "**(B) Editing and submitting the content of this Jupyter notebook, through Courseworks; **\n",
    "(i) The code for your CNN model and for the training function. The code should be stored in __./ecbm4040/neuralnets/kaggle.py__;\n",
    "(ii) Print out your training process and accuracy __within this notebook__;\n",
    "\n",
    "**(C) Submitting your best CNN model through Github Classroom repo.**\n",
    "\n",
    "**Description of (C):** \n",
    "For this task, we will continue to use Github classroom to save your model for submission. \n",
    "\n",
    "<span style=\"color:red\">__Submission content:__ :</span>\n",
    "(i) In your Assignment 2 submission folder, create a subfolder called __KaggleModel__. Upload your best model with all the data output (for example, __MODEL.data-00000-of-00001, MODEL.meta, MODEL.index__) into the folder. \n",
    "(ii) Remember to delete any intermediate results, **we only want your best model. Do not upload any data files**. The instructors will rerun the uploaded best model and verify against the score which you reported on the Kaggle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from scipy import misc\n",
    "from utils.image_generator import ImageGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e4040-2019fall-assign2-wc2685e/4040fall2019-assignment-2-task-5/kaggle_train_128/train_128/0/2999.png\n",
      "/Users/wenjiechen/Documents/GitHub/e4040-2019fall-assign2-wc2685\n"
     ]
    }
   ],
   "source": [
    "print('e4040-2019fall-assign2-wc2685e/4040fall2019-assignment-2-task-5/kaggle_train_128/train_128/0/' + str(i)+'.png')\n",
    "print(os.path.abspath('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13500, 128, 128, 3)\n",
      "(13500,)\n",
      "(1500, 128, 128, 3)\n",
      "(1500,)\n"
     ]
    }
   ],
   "source": [
    "X_all=np.zeros([15000,128,128,3])\n",
    "y_all=np.zeros(15000)\n",
    "for i in range(3000):\n",
    "    X_all[5*i]=mpimg.imread('e4040fall2019-assignment-2-task-5/kaggle_train_128/train_128/0/' + str(i)+'.png')\n",
    "    X_all[5*i+1]=mpimg.imread('e4040fall2019-assignment-2-task-5/kaggle_train_128/train_128/1/'+str(3000+i)+'.png')\n",
    "    X_all[5*i+2]=mpimg.imread('e4040fall2019-assignment-2-task-5/kaggle_train_128/train_128/2/'+str(6000+i)+'.png')\n",
    "    X_all[5*i+3]=mpimg.imread('e4040fall2019-assignment-2-task-5/kaggle_train_128/train_128/3/'+str(9000+i)+'.png')\n",
    "    X_all[5*i+4]=mpimg.imread('e4040fall2019-assignment-2-task-5/kaggle_train_128/train_128/4/'+str(12000+i)+'.png')\n",
    "    y_all[5*i]=0\n",
    "    y_all[5*i+1]=1\n",
    "    y_all[5*i+2]=2\n",
    "    y_all[5*i+3]=3\n",
    "    y_all[5*i+4]=4\n",
    "    \n",
    "X_val=X_all[-1500:]\n",
    "y_val=y_all[-1500:]\n",
    "\n",
    "X_train=X_all[:-1500]\n",
    "y_train=y_all[:-1500]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "X_test=np.zeros([3500,128,128,3])\n",
    "y_all=np.zeros(3500)\n",
    "for i in range(3000):\n",
    "    X_test[i]=mpimg.imread('e4040fall2019-assignment-2-task-5/kaggle_test_128/test_128/'+str(i)+'.png')\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building example LeNet. Parameters: \n",
      "conv_featmap=[32, 32, 32]\n",
      "fc_units=[84, 84]\n",
      "conv_kernel_size=[5, 5, 5]\n",
      "pooling_size=[2, 2, 2]\n",
      "l2_norm=0.01\n",
      "seed=235\n",
      "learning_rate=0.01\n",
      "number of batches for training: 55\n",
      "epoch 1 \n",
      "epoch 2 \n",
      "Best validation accuracy! iteration:100 accuracy: 38.0%\n",
      "epoch 3 \n",
      "epoch 4 \n",
      "Best validation accuracy! iteration:200 accuracy: 72.93333333333334%\n",
      "epoch 5 \n",
      "epoch 6 \n",
      "epoch 7 \n",
      "epoch 8 \n",
      "epoch 9 \n",
      "epoch 10 \n",
      "epoch 11 \n",
      "epoch 12 \n",
      "epoch 13 \n",
      "epoch 14 \n",
      "epoch 15 \n",
      "Best validation accuracy! iteration:800 accuracy: 78.46666666666667%\n",
      "epoch 16 \n",
      "epoch 17 \n",
      "epoch 18 \n",
      "epoch 19 \n",
      "Best validation accuracy! iteration:1000 accuracy: 80.73333333333333%\n",
      "epoch 20 \n",
      "Traning ends. The best valid accuracy is 80.73333333333333. Model named lenet_1572726586.\n"
     ]
    }
   ],
   "source": [
    "from utils.neuralnets.cnn.kaggle import my_training_task5\n",
    "tf.reset_default_graph()\n",
    "\n",
    "my_training_task5(X_train, y_train, X_val, y_val,\n",
    "                conv_featmap=[32,32,32],\n",
    "                fc_units=[84,84],\n",
    "                conv_kernel_size=[5,5,5],\n",
    "                pooling_size=[2,2,2],\n",
    "                l2_norm=0.01,\n",
    "                seed=235,\n",
    "                learning_rate=1e-2,\n",
    "                epoch=20,\n",
    "                batch_size=245,\n",
    "                verbose=False,\n",
    "                pre_trained_model=None)\n",
    "\n",
    "# The following is the code given in task 3 to play around the data first...\n",
    "# from utils.neuralnets.cnn.LeNet_model import training\n",
    "# tf.reset_default_graph()\n",
    "# training(X_train, y_train, X_val, y_val, \n",
    "#          conv_featmap=[6],\n",
    "#          fc_units=[84],\n",
    "#          conv_kernel_size=[5],\n",
    "#          pooling_size=[2],\n",
    "#          l2_norm=0.01,\n",
    "#          seed=235,\n",
    "#          learning_rate=1e-4,\n",
    "#          epoch=20,\n",
    "#          batch_size=295,\n",
    "#          verbose=False,\n",
    "#          pre_trained_model=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The test acc of this final model (made small bad changes)is 84%.\n",
    "# The model I have run before with a little high acc (89%) can't git-revert to it, so I can only submit the previous ipynb.\n",
    "# And I guess there is something wrong between my epoch 3&4, causing the acc suddenly changes to a high point that 5-15 can't beat it. \n",
    "\n",
    "# However, my Google cloud GPU doesn't work, so I run the model on my localhost CPU. It took 2 hours.\n",
    "# That's why I didn't run the model again or debug it (maybe it's only randomness), and let the weird thing on it...\n",
    "\n",
    "# Referenced: http://www.voidcn.com/article/p-fyveipad-ct.html\n",
    "# https://www.ctolib.com/topics-120513.html\n",
    "# http://deeplearning.net/tutorial/lenet.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building my LeNet. Parameters: \n",
      "conv_featmap=[32, 32, 32]\n",
      "fc_units=[84, 84]\n",
      "conv_kernel_size=[5, 5, 5]\n",
      "pooling_size=[2, 2, 2]\n",
      "l2_norm=0.01\n",
      "seed=235\n",
      "learning_rate=0.01\n",
      "number of batches for training: 3500\n",
      "Load the model from: lenet_1572726586\n",
      "INFO:tensorflow:Restoring parameters from model/lenet_1572726586\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from utils.neuralnets.cnn.kaggle import test\n",
    "tf.reset_default_graph()\n",
    "predicted2,merge_all=test(X_test, y_all, \n",
    "                conv_featmap=[32,32,32],\n",
    "                fc_units=[84,84],\n",
    "                conv_kernel_size=[5,5,5],\n",
    "                pooling_size=[2,2,2],\n",
    "                l2_norm=0.01,\n",
    "                seed=235,\n",
    "                learning_rate=1e-2,\n",
    "                epoch=20,\n",
    "                batch_size=245,\n",
    "                verbose=False,\n",
    "                pre_trained_model='lenet_1572726586')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate .csv file for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code snippet can be used to generate your prediction .csv file.\n",
    "\n",
    "import csv\n",
    "with open('predicted2.csv','w') as csvfile:\n",
    "    fieldnames = ['Id','label']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for index,l in enumerate(predicted):\n",
    "        filename = str(index)+'.png'\n",
    "        label = str(l)\n",
    "        writer.writerow({'Id': filename, 'label': label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
